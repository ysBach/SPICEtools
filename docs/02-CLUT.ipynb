{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crude (CLUT) Calculation\n",
    "\n",
    "The purpose of this notebook is to \n",
    "1. Do a crude 1-year SPICE calculation of all small bodies (crude look-up table, CLUT).\n",
    "    * In this example, I will make a crude calculation for the year 2025. \n",
    "    * The calculation starts on 2025-02-01 for 350 days (for every 1-day)\n",
    "    * Since this is a \"crude\" calculation, any aberration corrections will be ignored (which doubles the calculation speed), and the observer is a geocenter (not a spacecraft - you can change this, but the computation time may be roughly doubled if ``spkcvo`` is used).\n",
    "    * ~ 6kB/object, so 1.3M objects correspond to ~10 GB.\n",
    "\n",
    "\n",
    "For doing so, we need a snapshot of the SBDB list & BSP files.\n",
    "\n",
    "In this example, I used those queried on **UT2023-12-28**. As of writing (2024 Aug), necessary files are availble via my personal Dropbox:\n",
    "* SBDB query parquet files (~300MB): [link](https://www.dropbox.com/scl/fo/opi6k5b49bky6bomb6gmt/ACBDWV3cEECB2JH0X2GqAog?rlkey=injz3wl48ff7ci68djelbjkd6&dl=0) \n",
    "* Horizons-queried BSP files (~46GB): [link](https://www.dropbox.com/scl/fi/9xr7hpxy7b8p1z856623a/spkbsp.zip?rlkey=ffnky4jq3qhw34tqqbylng4ep&dl=0) (user needs to unzip this)\n",
    "\n",
    "Save them to a certain location, and modify the PATHS variable below accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Comets   : 986\n",
      "Number of Asteroids: 1339872\n"
     ]
    }
   ],
   "source": [
    "import spicetools as spt\n",
    "import spiceypy as sp\n",
    "from astropy.time import Time\n",
    "import ctypes\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyarrow import dataset as ds\n",
    "\n",
    "from astropy import units as u\n",
    "\n",
    "def iterator(it):\n",
    "    try:\n",
    "        from tqdm import tqdm\n",
    "        return tqdm(it)\n",
    "    except ImportError:\n",
    "        return it\n",
    "# ---------------------------------------------------------------------------------------------------------- #\n",
    "# CHANGE HERE\n",
    "PATHS = dict(\n",
    "    # SPICE kernels\n",
    "    SPICE=dict(\n",
    "        TLS=\"$KERNELS/lsk/naif0012.tls\",\n",
    "        GM=\"$KERNELS/pck/gm_de440.tpc\",\n",
    "        PCK=\"$KERNELS/pck/pck00011.tpc\",\n",
    "        DE=\"$KERNELS/de432s.bsp\"\n",
    "    ),\n",
    "    ORBROOT=\"../../../../workspace/__Database/orbits\",\n",
    "    SBDB=dict(\n",
    "        ast=\"../../../../workspace/__Database/orbits/sbdb_query_20231228/sbdb_a.parq\",\n",
    "        com=\"../../../../workspace/__Database/orbits/sbdb_query_20231228/sbdb_c.parq\",\n",
    "    ),\n",
    "    clutparent=\"clut\"\n",
    ")\n",
    "# $KERNELS is a magic word for the path to the SPICE kernels included in this repo.\n",
    "# You can find them in `src/spicetools/kernels` directory of this repo.\n",
    "# ORBROOT is the parent directory where the BSP files are located. You may freely change it.\n",
    "# ---------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "chunk = 100000  # Number of objects to be saved into a single parquet file\n",
    "Path(PATHS[\"clutparent\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "########## SPICE INITIALIZATION ##########\n",
    "# Make the SPICE \"meta kernel\" for this example\n",
    "TMP_META_PATH = Path(\"test.mk\")\n",
    "spt.make_meta(*PATHS[\"SPICE\"].values(), output=TMP_META_PATH)\n",
    "# Load (\"furnish\" in SPICE)\n",
    "handle_meta = sp.furnsh(str(TMP_META_PATH))\n",
    "\n",
    "########## SBDB/BSP DATA (LIKELY BE DOWNLOADED/MANAGED SEPARATELY) ##########\n",
    "dtypes = {\n",
    "    \"spkid\": int, \"pdes\":str, \"full_name\": str, \"kind\": str, \"condition_code\": str\n",
    "}\n",
    "_dataset = ds.dataset(PATHS[\"SBDB\"][\"ast\"], format=\"parquet\")\n",
    "# Use filter to take objects with (1) proper U-parameter & (2) proper H magnitude (for flux modeling)\n",
    "dfa = _dataset.to_table(\n",
    "    columns=list(dtypes.keys()) + [\"H\", \"G\"],\n",
    "    filter=(ds.field(\"condition_code\").isin(list(\"0123456789\"))) & (ds.field(\"H\") < 100)\n",
    ")\n",
    "\n",
    "_dataset = ds.dataset(PATHS[\"SBDB\"][\"com\"], format=\"parquet\")\n",
    "# Use filter to take objects meaningful entry...\n",
    "dfc = _dataset.to_table(\n",
    "    columns=list(dtypes.keys()) + [\"M1\", \"M2\", \"K1\", \"K2\"],\n",
    "    filter=((ds.field(\"condition_code\").isin(list(\"0123456789\"))) & (ds.field(\"data_arc\") > 0)\n",
    "            & ((ds.field(\"M1\") < 100) | (ds.field(\"M2\") < 100) | (ds.field(\"K1\") < 100) | (ds.field(\"K2\") < 100)))\n",
    ")\n",
    "\n",
    "dfs = dict(c=dfc.to_pandas(), a=dfa.to_pandas())\n",
    "del dfa, dfc\n",
    "\n",
    "print(f\"Number of Comets   : {len(dfs['c'])}\\nNumber of Asteroids: {len(dfs['a'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Optimization for SPICE\n",
    "\n",
    "Since the SPICE used in `spiceypy` is written in C (CSPICE), every `spiceypy` function will have to convert the input Python variable into C-type objects. This actually results in non-negligible overhead for our case because we have a nested for-loop to call the SPICE function for 1.3M objects * 350 timestamps. \n",
    "\n",
    "Changing many input parameters to C-types prior to the for-loop actually nearly doubles the computation speed in our case (on my laptop...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precalculate all ET values\n",
    "TIMES, ETS = spt.times2et(Time(\"2025-02-01\") + np.arange(350)*u.day)\n",
    "ETS_C = [ctypes.c_double(_et) for _et in ETS]  # ctype\n",
    "\n",
    "ref = sp.stypes.string_to_char_p(\"ECLIPJ2000\")\n",
    "obs = ctypes.c_int(399)\n",
    "_ptarg = sp.stypes.empty_double_vector(3)\n",
    "_lt = ctypes.byref(ctypes.c_double())\n",
    "NO_SPK_FILE = []\n",
    "ERROR_FILE = []\n",
    "\n",
    "\n",
    "def spkgps(targ, et):\n",
    "    sp.libspice.spkgps_c(targ, et, ref, obs, _ptarg, _lt)\n",
    "\n",
    "\n",
    "def calc_spice(spkids, parent, outpath):\n",
    "    spkids_used = []\n",
    "    xs, ys, zs = [], [], []\n",
    "    for spkid in iterator(spkids):\n",
    "        fpath = f\"{parent}/spk{spkid}.bsp\"\n",
    "        try:\n",
    "            handle = sp.spklef(fpath)\n",
    "            targ_pos = []\n",
    "            _target = ctypes.c_int(int(spkid))\n",
    "            for _et in ETS_C:\n",
    "                spkgps(_target, _et)\n",
    "                # Below is an optimized version of sp.stypes.c_vector_to_python\n",
    "                targ_pos.append(np.frombuffer(_ptarg).copy())\n",
    "\n",
    "            sp.spkuef(handle)\n",
    "        except:  # Some unexpected errors\n",
    "            if not Path(fpath).exists():\n",
    "                NO_SPK_FILE.append(spkid)\n",
    "                continue\n",
    "            ERROR_FILE.append(spkid)\n",
    "            continue\n",
    "\n",
    "        spkids_used.append(spkid)\n",
    "        targ_pos = np.array(targ_pos).astype(np.float32)\n",
    "        x, y, z = targ_pos.T\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        zs.append(z)\n",
    "\n",
    "    xyz = np.hstack([xs, ys, zs]).astype(np.float32)\n",
    "    df = pd.DataFrame(xyz, columns=[str(i) for i in range(xyz.shape[1])])\n",
    "    df.insert(loc=0, value=np.array(spkids_used).astype(np.int32), column=\"spkid\")\n",
    "    df.to_parquet(outpath)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to crude/c_chunk_000.parq: N_obj=986; took 2.08 sec\n",
      "Saved to crude/a_chunk_000.parq: N_obj=100000; took 205.72 sec\n",
      "Saved to crude/a_chunk_001.parq: N_obj=100000; took 231.86 sec\n",
      "Saved to crude/a_chunk_002.parq: N_obj=100000; took 244.91 sec\n",
      "Saved to crude/a_chunk_003.parq: N_obj=100000; took 239.03 sec\n",
      "Saved to crude/a_chunk_004.parq: N_obj=100000; took 242.68 sec\n",
      "Saved to crude/a_chunk_005.parq: N_obj=100000; took 224.85 sec\n",
      "Saved to crude/a_chunk_006.parq: N_obj=100000; took 233.65 sec\n",
      "Saved to crude/a_chunk_007.parq: N_obj=100000; took 235.87 sec\n",
      "Saved to crude/a_chunk_008.parq: N_obj=100000; took 235.48 sec\n",
      "Saved to crude/a_chunk_009.parq: N_obj=100000; took 237.18 sec\n",
      "Saved to crude/a_chunk_010.parq: N_obj=100000; took 235.20 sec\n",
      "Saved to crude/a_chunk_011.parq: N_obj=100000; took 231.10 sec\n",
      "Saved to crude/a_chunk_012.parq: N_obj=100000; took 229.00 sec\n",
      "Saved to crude/a_chunk_013.parq: N_obj=39872; took 89.23 sec\n"
     ]
    }
   ],
   "source": [
    "for ac in \"ca\":\n",
    "    _df = dfs[ac]\n",
    "    bspparent = f\"{PATHS['ORBROOT']}/spkbsp/{ac}\"\n",
    "    for i in range(len(_df)//chunk + 1):\n",
    "        _t = Time.now()\n",
    "        outpath = f\"{PATHS['clutparent']}/{ac:s}_chunk_{i:03d}.parq\"\n",
    "        _spkids = _df[\"spkid\"][i*chunk:(i+1)*chunk]\n",
    "        calc_spice(_spkids, bspparent, outpath)\n",
    "        print(f\"Saved to {outpath}: N_obj={len(_spkids)}; took {(Time.now() - _t).value*86400:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPK file not found: [20101955]\n",
      "Calculation error : [1000084, 1000096, 1000143, 1000145, 1000237, 1000242, 1000365, 1000374, 1000468, 1000522, 20139754, 20196150, 20500577, 20546918, 20571179, 20582878, 20628041, 20628042, 54126829, 54405815, 54410854, 54414532]\n"
     ]
    }
   ],
   "source": [
    "NO_SPK_FILE.sort()\n",
    "ERROR_FILE.sort()\n",
    "print(\"SPK file not found:\", NO_SPK_FILE)\n",
    "print(\"Calculation error :\", ERROR_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the calculation error is not a serious one, especially if the SPKID is smaller than 20,000,000 (any asteroid with good orbital constraints is given an ID larger than 20M. Comets, which may disappear/disrupted, or asteroids with uncertain orbits, will be given smaller numbers.)\n",
    "\n",
    "For (101955) Bennu, there is a known problem for its BSP. Since it is a very faint target, I want to completely ignore it even though it is an interesting target (OSIRIS-REx mission target)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
